{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "- Change GPU to extra large over lunch\n",
    "- ReadMe on Matterport\n",
    "- Read : train_shapes, config to understand parameters adnd the shape of the output.\n",
    "- Code dataframe function for model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the first cell if you have re-initialised your server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.15.3 \n",
    "! pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install keras==2.0.8\n",
    "! pip show keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrcnn\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "import skimage\n",
    "import numpy as np\n",
    "import colorsys\n",
    "import argparse\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import shutil\n",
    "import pprint\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "WEIGHTS_PATH = os.path.join(ROOT_DIR, \"notebooks/Mask_RCNN/mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the image and label paths for train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(glob.glob(\"../../inputs/train/images/*jpg\"))\n",
    "label_paths = sorted(glob.glob(\"../../inputs/train/labels/*json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a custom configuration for our construction Mask-RCNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstructionConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"construction\"\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 2  # Background + balloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 50\n",
    "\n",
    "    # Skip detections with < 70% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConstructionConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our model configuration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonnes metrics ? MAP / IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTRUCTION_DIR = \"../../inputs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create your train and validation folders and subfolders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_split_data():\n",
    "    \"\"\"\n",
    "    Returns True if the data has already been split, False otherwise.\n",
    "    \"\"\"\n",
    "    TRAIN_FOLDER_EXISTS = (\"train\" in os.listdir(\"../../inputs\"))\n",
    "    VAL_FOLDER_EXISTS = (\"val\" in os.listdir(\"../../inputs\"))  \n",
    "    \n",
    "    if TRAIN_FOLDER_EXISTS or VAL_FOLDER_EXISTS:\n",
    "        TRAIN_OR_VAL_HAS_ELEMENTS = (len(os.listdir(\"../../inputs/train/images\")) > 0) or (len(os.listdir(\"../../inputs/train/labels\")) > 0)\n",
    "        print(f\"There are {len(os.listdir('../../inputs/train/images'))} images in train.\")\n",
    "        print(f\"There are {len(os.listdir('../../inputs/val/images'))} images in val.\")\n",
    "        if TRAIN_OR_VAL_HAS_ELEMENTS:\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Folders exist but are empty.\")\n",
    "            print(f\"There are {len(os.listdir('../../inputs/images'))} images in the root folder.\")\n",
    "            print(f\"There are {len(os.listdir('../../inputs/labels'))} labels in the root folder.\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"There are no train or val folders.\")\n",
    "        print(f\"There are {len(os.listdir('../../inputs/images'))} images in the root folder.\")\n",
    "        print(f\"There are {len(os.listdir('../../inputs/labels'))} labels in the root folder.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell moves all your images and labels back to their root folders if they have been split in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_split_data():\n",
    "    ! mv ../../inputs/train/labels/* ../../inputs/labels\n",
    "    ! mv ../../inputs/train/images/*  ../../inputs/images\n",
    "    ! mv ../../inputs/val/labels/* ../../inputs/labels\n",
    "    ! mv ../../inputs/val/images/* ../../inputs/images\n",
    "    print(f\"There are now {len(os.listdir('../../inputs/images'))} images in the root folder.\")\n",
    "    print(f\"There are now {len(os.listdir('../../inputs/labels'))} labels in the root folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the folders do not exist, this cell will create the train and val directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER_EXISTS = (\"train\" in os.listdir(\"../../inputs\"))\n",
    "VAL_FOLDER_EXISTS = (\"val\" in os.listdir(\"../../inputs\"))\n",
    "\n",
    "if TRAIN_FOLDER_EXISTS == False or VAL_FOLDER_EXISTS == False:\n",
    "    ! mkdir \"../../inputs/train\" \"../../inputs/val\"\n",
    "    ! mkdir \"../../inputs/train/images\" \"../../inputs/train/labels\"\n",
    "    ! mkdir \"../../inputs/val/images\" \"../../inputs/val/labels\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_set(train_percent = 0.8):\n",
    "    \"\"\"\n",
    "    Create a random train and validation split. \n",
    "    \"\"\"\n",
    "    INPUTS_DIR = \"../../inputs\"\n",
    "    TRAIN_DIR = \"../../inputs/train/\"\n",
    "    VAL_DIR = \"../../inputs/val/\"\n",
    "\n",
    "    # Retrieve all image and label paths\n",
    "    image_paths = sorted(glob.glob(os.path.join(INPUTS_DIR, \"images/*jpg\")))\n",
    "    label_paths = sorted(glob.glob(os.path.join(INPUTS_DIR, \"labels/*json\")))\n",
    "    n = len(image_paths)\n",
    "    train_nb = np.floor(train_percent*n).astype(int)\n",
    "    indices = random.sample(range(n), train_nb)\n",
    "    train_image_paths, train_label_paths = [image_paths[i] for i in indices], [label_paths[i] for i in indices]\n",
    "    valid_image_paths, valid_label_paths = [image_paths[i] for i in range(n-1) if i not in indices], [label_paths[i] for i in range(n-1) if i not in indices]\n",
    "    for image_path in train_image_paths:\n",
    "        shutil.move(image_path, TRAIN_DIR+\"images\")\n",
    "    for image_path in valid_image_paths:\n",
    "        shutil.move(image_path, VAL_DIR+\"images\")\n",
    "    for label_path in train_label_paths:\n",
    "        shutil.move(label_path, TRAIN_DIR+\"labels\")\n",
    "    for label_path in valid_label_paths:\n",
    "        shutil.move(label_path, VAL_DIR+\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate train_validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_set(train_percent = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(os.listdir('../../inputs/train/images'))} images in train.\")\n",
    "print(f\"There are {len(os.listdir('../../inputs/val/images'))} images in val.\")\n",
    "print(f\"There are {len(os.listdir('../../inputs/images'))} images in the root folder.\")\n",
    "print(f\"There are {len(os.listdir('../../inputs/labels'))} labels in the root folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Construction Dataset object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads and pre-processes the data to feed the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define some support functions for this notebook. (they should later on be added to utils, and imported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utils functions we define locally\n",
    "\n",
    "def load_labels_from_folder(label_paths):\n",
    "    \"\"\"\n",
    "    Load and pre-format labels to feed to ConstructionDataset. \n",
    "    folder: folder to retrieve the labels from\n",
    "    \"\"\"\n",
    "    labels = list()\n",
    "    for label_path in label_paths:\n",
    "        with open(label_path) as json_data:\n",
    "            lbl = reformat_label(json.load(json_data), label_path)\n",
    "            if lbl is not None:\n",
    "                labels.append(lbl)\n",
    "    return labels\n",
    "\n",
    "def reformat_label(label, label_path):\n",
    "    \"\"\"\n",
    "    Reformat label to correspond to VGG annotator standard. \n",
    "    \"\"\"\n",
    "    objects = label[\"objects\"]\n",
    "    filename = os.path.split(label_path)[-1] # retrieve filename from full path\n",
    "    object_list = []\n",
    "    objects = list(filter(is_polygon, objects))\n",
    "    for i in range(len(objects)):\n",
    "        object_list.append(reshape_poly_coordinates(objects[i]))\n",
    "    return {\n",
    "            'filename': filename,\n",
    "             'objects': {\"region_attributes\" : {},\n",
    "                        \"shape_attributes\" : object_list},\n",
    "             'size': label[\"size\"]\n",
    "            }\n",
    "\n",
    "def is_polygon(obj):\n",
    "    \"\"\"\n",
    "    Boolean determining whether an object is a polygon or not. \n",
    "    obj: a label pertaining to an image\n",
    "    \"\"\"\n",
    "    if obj['geometryType'] == 'polygon':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def reshape_poly_coordinates(object_label):\n",
    "    \"\"\"\n",
    "    Reshape polygons points to generate the mask. \n",
    "    \"\"\"\n",
    "    ext_points = object_label[\"points\"][\"exterior\"]\n",
    "    # TO DO - find how to fix interior points\n",
    "    return {\n",
    "            \"all_points_x\": [x[0] for x in ext_points],\n",
    "            \"all_points_y\" : [x[1] for x in ext_points],\n",
    "            \"name\":\"polygon\",\n",
    "            \"class\": object_label[\"classTitle\"]\n",
    "        }\n",
    "\n",
    "def filter_on_image_id(image_info_list,image_id):\n",
    "    \"\"\"\n",
    "    Return the image_info dictionary corresponding to the specified image_id. \n",
    "    \"\"\"\n",
    "    all_ids = [my_dict[\"id\"] for my_dict in image_info_list]\n",
    "    index = all_ids.index(image_id)\n",
    "    if image_info_list[index]:\n",
    "        return image_info_list[index]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def draw_polygon(image_dict : dict):\n",
    "    class_colors = {'Vertical_formwork': (255,0,255),\n",
    "                    'Concrete_pump_hose': (0,0,255)}\n",
    "    img = pyplot.imread(image_dict[\"path\"])\n",
    "    img_copy = img.copy()\n",
    "    for shape in image_dict[\"shapes\"]:\n",
    "        points = np.array(tuple([x, y] for x, y in zip(shape[\"all_points_x\"], shape[\"all_points_y\"])))\n",
    "        cv2.fillPoly(img, pts= [points], color=class_colors[shape.get('class')])\n",
    "        out = cv2.addWeighted(img_copy, .6, img, 0.4, 1)\n",
    "    pyplot.imshow(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstructionDataset(utils.Dataset):\n",
    "\n",
    "    def load_images(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the construction dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. Note that we inherit the \"BG\" (background) class from Dataset.\n",
    "        ## For now, we train our model only on polygons\n",
    "        self.add_class(\"construction\", 1, \"Vertical_formwork\")\n",
    "        self.add_class(\"construction\", 2, \"Concrete_pump_hose\")\n",
    "        #self.add_class(\"construction\", 3, \"People\")\n",
    "        #self.add_class(\"construction\", 4, \"Mixer_truck\")\n",
    "        \n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        label_paths = sorted(glob.glob(os.path.join(dataset_dir,\"labels\",\"*json\")))\n",
    "        annotations = load_labels_from_folder(label_paths)\n",
    "        i = 0\n",
    "        for a in annotations:\n",
    "            objects = a[\"objects\"]\n",
    "            shapes = objects[\"shape_attributes\"]\n",
    "            height, width = a['size'][\"height\"], a['size'][\"width\"]\n",
    "            img_filename = \".\".join(a['filename'].split(\".\")[:-1]) # removing the .json extension\n",
    "            image_path = os.path.join(dataset_dir,\"images\",img_filename)\n",
    "            self.add_image(\n",
    "                source = \"construction\",\n",
    "                image_id= i, #img_filename,  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                shapes=shapes)\n",
    "            i +=1\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = filter_on_image_id(self.image_info, image_id)\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"shapes\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"shapes\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs = 30, layers = \"heads\"):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    CONSTRUCTION_DIR = \"../../inputs\"\n",
    "    # Training dataset.\n",
    "    dataset_train = ConstructionDataset()\n",
    "    dataset_train.load_images(CONSTRUCTION_DIR, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = ConstructionDataset()\n",
    "    dataset_val.load_images(CONSTRUCTION_DIR, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=epochs,\n",
    "                layers=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ConstructionDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the load_images method, and check that data has initialised your objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO check shapes format in load_images\n",
    "# TO DO extend labelling outside polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_images(CONSTRUCTION_DIR, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our class instantiation. \"BG\" is a default class corresponding to a background object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.class_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the format of our image info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(data.image_info[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the label encoding was a success, let us visualise the labels for one of the images, based on image_info: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0,len(data.image_info))\n",
    "test_img = data.image_info[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(draw_polygon(test_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (instantiation and training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.py implementation does not work with the latest versions of tensorflow. Run the following command on your terminal to install the correct version of tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(\n",
    "    mode=\"training\", \n",
    "    config=config,\n",
    "    model_dir=MODEL_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the weights you want to initialise your model with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes I brought to the sourcecode: \n",
    "- [tf.Variable error linked to tensorflow version](https://github.com/matterport/Mask_RCNN/issues/1930). Changed tensorflow and keras versions to the ones in the beginning of the  notebook - This environment\n",
    "- Changed number of classes to 4 in ConstructionConfig() - This notebook\n",
    "- Commented multiprocessing to false in the model train method in model.py, changed the number of workers - model.py\n",
    "- Changed Keras versions again before training the model? TBC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, epochs=1, layers=\"heads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model you previously saved with the right weights and test it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ConstructionConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evauation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = ConstructionDataset()\n",
    "dataset_val.load_images(CONSTRUCTION_DIR, \"val\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
